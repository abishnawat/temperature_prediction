
R version 3.4.1 (2017-06-30) -- "Single Candle"
Copyright (C) 2017 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> weather<- read.csv("C:/Users/DELL/Desktop/minor project/weather_data_10yrs.csv")
> smp_size <- floor(0.75*nrow(weather))
> set.seed(500)
> index <- sample(seq_len(nrow(weather)), size=smp_size)
> wtrain <- weather[index, ]
> wtest <- weather[-index, ]
> normalize<-function(x){return((x-min(x))/(max(x)-min(x)))}
> weather_norm<-as.data.frame(lapply(weather, normalize))
> wtrain<-weather_norm[index, ]
> wtest <- weather_norm[-index, ]
> library(neuralnet)
> m<-neuralnet(X2016~X2015+X2014+X2013+X2012+X2011+X2010+X2009+X2008+X2007, data=wtrain, hidden=c(20,20,20,20,20), linear.output=T, stepmax=2e6)
> plot(nn)
> plot(m)
> pnn<-compute(m,wtest[,2:10])
> pr<-pnn$net.result
> cor(wtest$X2016, pr)
             [,1]
[1,] 0.7205459102
> library(Metrics)
> mse(wtest$X2016, pr)
[1] 0.03886893615
> summary(wtest$X2016)
     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
0.0000000 0.3626418 0.6507293 0.6008209 0.8253647 0.9821718 
> summary(pr)
       V1             
 Min.   :-0.07046291  
 1st Qu.: 0.38985682  
 Median : 0.65419929  
 Mean   : 0.61171413  
 3rd Qu.: 0.87008034  
 Max.   : 1.03274733  
> wtest.x<-((wtest$X2016)*(max(weather)-min(weather)))+min(weather)
> pr.x<-(pr*(max(weather)-min(weather)))+min(weather)
> cor(wtest.x, pr.x)
             [,1]
[1,] 0.7205459102
> mse(wtest.x, pr.x)
[1] 206.565463
> m<-neuralnet(X2016~X2015+X2014+X2013+X2012+X2011+X2010+X2009+X2008+X2007, data=wtrain, hidden=c(5,3), linear.output=T, stepmax=2e6)
> plot(m)
> q()
> pnn<-compute(m, wtest[2:10])
> pr<-pnn$net.result
> cor(wtest$X2016, pr)
             [,1]
[1,] 0.7575724472
> pr.x<-(pr*(max(weather)-min(weather)))+min(weather)
> mse(wtest.x, pr.x)
[1] 173.814983
> pr.x
            [,1]
1   22.801650605
7   18.403551327
8   13.471474339
10  29.712678828
15  22.955039905
19  37.111748613
20  33.585103237
21  30.484109116
24  32.802181435
32  26.562400443
34  29.516938748
41  22.430722763
45  45.694161936
46  29.508459084
49  51.318991468
57  22.681742930
61  26.426406689
72  35.861175693
78  27.755079866
80   1.928537149
81  42.785231551
84  33.396287972
86  22.695873486
87  23.044194566
90  50.280589451
91  43.552307360
97  49.749668721
108 36.677552584
112 54.633325369
119 53.364602030
120 52.870247549
121 58.193731312
123 62.411990744
124 58.430298828
127 55.129505202
128 61.545661174
130 53.856420291
140 70.848032846
146 60.053350560
150 65.576553009
152 70.986864351
159 72.594017044
161 74.803671701
164 70.504101054
165 67.519540399
166 67.926571483
174 72.049111381
177 73.046271081
179 74.439569245
182 69.346802468
186 70.984177284
188 73.564115830
193 72.457647573
199 73.158791421
200 76.037964908
204 72.286607924
207 70.068727638
214 71.645143094
216 73.167320809
217 73.705280052
218 74.713766141
224 68.896668753
237 72.263909124
241 72.475248562
242 71.433114351
247 70.502962601
255 71.754067380
259 63.321037467
265 68.338933238
267 61.231938716
281 62.479520958
283 62.809460038
291 58.131310137
293 39.010847523
295 51.436016456
298 60.940492982
308 46.776988159
310 52.661382085
313 50.721906955
314 50.251364449
315 51.368560263
320 27.632192790
321 29.708238188
323 45.006584215
325 24.430125608
329 50.412297909
336 31.842721053
339 19.440538770
342 37.895800456
347 42.799074733
352 29.506607387
362 33.911066897
> wtest.x
 [1] 39.92820097 32.83905997 36.26547812 32.83905997 30.59416532 10.50826580 10.50826580 20.07860616 22.44165316 44.53614263 49.49854133 17.83371151  7.20000000
[14] 16.53403566 26.93144246 25.86807131 30.59416532 60.13225284 39.92820097 32.83905997 26.93144246 64.74019449 52.92495948 52.92495948 54.10648298 68.16661264
[27] 51.86158833 38.86482982 62.49529984 60.13225284 57.53290113 58.83257699 63.55867099 54.10648298 48.19886548 60.13225284 65.80356564 55.16985413 64.74019449
[40] 67.10324149 68.16661264 57.53290113 58.83257699 62.49529984 58.83257699 71.82933549 68.16661264 64.74019449 73.12901135 74.19238250 75.37390600 75.37390600
[53] 71.82933549 74.19238250 76.43727715 74.19238250 77.73695300 75.37390600 70.76596434 75.37390600 76.43727715 78.80032415 65.80356564 70.76596434 68.16661264
[66] 61.19562399 70.76596434 69.46628849 73.12901135 64.74019449 63.55867099 42.29124797 60.13225284 61.19562399 38.86482982 41.22787682 42.29124797 32.83905997
[79] 44.53614263 32.83905997 31.65753647 30.59416532 32.83905997 38.86482982 21.14197731 50.56191248 28.23111831 38.86482982 33.90243112 33.90243112 39.92820097
[92] 31.65753647
> plot(m)
> wtrain<-weather[index, ]
> wtest<- weather[-index, ]
> m<-neuralnet(X2016~X2015+X2014+X2013+X2012+X2011+X2010+X2009+X2008+X2007, data=wtrain, hidden=c(5,3), linear.output=T, stepmax=2e6)
> pnn<-compute(m, wtest[2:10])
> pr<-pnn$net.result
> cor(wtest$X2016, pr)
     [,1]
[1,]   NA
Warning message:
In cor(wtest$X2016, pr) : the standard deviation is zero
> 
> m<-neuralnet(X2016~X2015+X2014+X2013+X2012+X2011+X2010+X2009+X2008+X2007, data=wtrain, hidden=c(5,3), linear.output=T, stepmax=2e6)
> pnn<-compute(m, wtest[2:10])
> > pr<-pnn$net.result
Error: unexpected '>' in ">"
> > cor(wtest$X2016, pr)
Error: unexpected '>' in ">"
> pr<-pnn$net.result
> cor(wtest$X2016, pr)
     [,1]
[1,]   NA
Warning message:
In cor(wtest$X2016, pr) : the standard deviation is zero
> pr
           [,1]
1   52.02124675
7   52.02124675
8   52.02124675
10  52.02124675
15  52.02124675
19  52.02124675
20  52.02124675
21  52.02124675
24  52.02124675
32  52.02124675
34  52.02124675
41  52.02124675
45  52.02124675
46  52.02124675
49  52.02124675
57  52.02124675
61  52.02124675
72  52.02124675
78  52.02124675
80  52.02124675
81  52.02124675
84  52.02124675
86  52.02124675
87  52.02124675
90  52.02124675
91  52.02124675
97  52.02124675
108 52.02124675
112 52.02124675
119 52.02124675
120 52.02124675
121 52.02124675
123 52.02124675
124 52.02124675
127 52.02124675
128 52.02124675
130 52.02124675
140 52.02124675
146 52.02124675
150 52.02124675
152 52.02124675
159 52.02124675
161 52.02124675
164 52.02124675
165 52.02124675
166 52.02124675
174 52.02124675
177 52.02124675
179 52.02124675
182 52.02124675
186 52.02124675
188 52.02124675
193 52.02124675
199 52.02124675
200 52.02124675
204 52.02124675
207 52.02124675
214 52.02124675
216 52.02124675
217 52.02124675
218 52.02124675
224 52.02124675
237 52.02124675
241 52.02124675
242 52.02124675
247 52.02124675
255 52.02124675
259 52.02124675
265 52.02124675
267 52.02124675
281 52.02124675
283 52.02124675
291 52.02124675
293 52.02124675
295 52.02124675
298 52.02124675
308 52.02124675
310 52.02124675
313 52.02124675
314 52.02124675
315 52.02124675
320 52.02124675
321 52.02124675
323 52.02124675
325 52.02124675
329 52.02124675
336 52.02124675
339 52.02124675
342 52.02124675
347 52.02124675
352 52.02124675
362 52.02124675
> plot(m)
> 
